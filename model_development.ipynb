{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62LQ_sSiqxOZ",
        "outputId": "81237da5-e01e-4b01-edcd-45b8772ed1b2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 705 kB 28.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 59.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 25.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 54.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 74.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 70.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 58.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 81.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 67.6 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! pip -q install pytorch_lightning transformers wandb sentence-transformers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g0HhrVdrqpd_",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19973572-88ac-4005-c82b-cffad4cda5e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import re\n",
        "import math\n",
        "import gc\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning\n",
        "\n",
        "device =  torch.device('cuda' if torch.has_cuda else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb2NUlVIgTtU",
        "outputId": "b9518bee-52f3-479a-fcab-0527853f9b01",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Aug 11 09:05:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Quadro P6000        Off  | 00000000:00:05.0 Off |                  Off |\n",
            "| 26%   28C    P8     8W / 250W |      2MiB / 24449MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Wn7aJTqpeB"
      },
      "source": [
        "# Load Dataset and pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Gf9uYYbOXM8"
      },
      "outputs": [],
      "source": [
        "# load the models \n",
        "! wget -q \"https://www.dropbox.com/s/58ns2jt8aj8yoxm/models.zip?dl=0\"\n",
        "! unzip -q models.zip?dl=0\n",
        "\n",
        "# load python dataset\n",
        "! wget -q \"https://www.dropbox.com/s/eijnvwna66sq0rq/python.zip?dl=0\"\n",
        "! unzip -q python.zip?dl=0\n",
        "\n",
        "# load javascript dataset\n",
        "! wget -q \"https://www.dropbox.com/s/rmzuylbwpj2l44y/javascript.zip?dl=0\"\n",
        "! unzip -q javascript.zip?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# please select between python or java script \n",
        "\n",
        "language = int( input(\"0: for python \\n1: for javascript\\n\") )\n",
        "\n",
        "\n",
        "if language == 0:\n",
        "\n",
        "  language = \"python\"\n",
        "\n",
        "  dir = f\"./{language}/\"\n",
        "  load_model = \"/content/models/python_model_2.ckpt\"\n",
        "else:\n",
        "\n",
        "  language = \"javascript\"\n",
        "\n",
        "  dir = f\"./{language}/\"\n",
        "  load_model = \"/content/models/js_model.ckpt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvNr1_bJOjkX",
        "outputId": "3da727c7-3815-4df7-9c40-5a17a0c28b00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: for python \n",
            "1: for javascript\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LcMiQ1SqpeD",
        "outputId": "f9a71f63-1627-4142-ef3b-95c9dd94bbfe",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((123889, 2), (8253, 2), (6483, 2))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def jsonl_list_to_dataframe(file_list, dir , columns=['code', 'docstring']):\n",
        "    \n",
        "    \"\"\"\n",
        "    input  : Directory \n",
        "    output : Dataframe that has code and docstring \n",
        "    \"\"\"\n",
        "\n",
        "    file_list =   glob.glob(f\"{dir}/**.gz\", recursive= True)\n",
        "\n",
        "    return pd.concat([pd.read_json( f, orient='records', compression='gzip', lines=True)[columns] for f in file_list], sort=False)\n",
        "\n",
        "def get_dfs(path):\n",
        "    \"\"\"\n",
        "    input  : Directory \n",
        "    output : returns train, Validation and test  dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    dfs = []\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        \n",
        "        files = sorted( os.listdir( path+split  ) )\n",
        "        df = jsonl_list_to_dataframe(files, path+split ) #.rename(columns = {'code': 'mthd', 'docstring': 'cmt'})\n",
        "        dfs.append( df )\n",
        "        \n",
        "    return dfs\n",
        "\n",
        "train, valid, test = get_dfs(dir)\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nlhwVQDIqpeD",
        "outputId": "f0115fc3-de27-4355-8e68-82eeedbbdb2c",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>docstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>function createTypeScriptLanguageService(optio...</td>\n",
              "      <td>#region Discovery, LanguageService &amp; Setup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>function discoverAndReadFiles(options) {\\n    ...</td>\n",
              "      <td>Read imports and follow them until all files h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>function getRealNodeSymbol(checker, node) {\\n ...</td>\n",
              "      <td>#endregion #region Utils \\nReturns the node's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>function shouldSkipAlias(node, declaration) {\\...</td>\n",
              "      <td>Go to the original declaration for cases:  (1)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>function getTokenAtPosition(sourceFile, positi...</td>\n",
              "      <td>Get the token whose text contains the position</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                code  \\\n",
              "0  function createTypeScriptLanguageService(optio...   \n",
              "1  function discoverAndReadFiles(options) {\\n    ...   \n",
              "2  function getRealNodeSymbol(checker, node) {\\n ...   \n",
              "3  function shouldSkipAlias(node, declaration) {\\...   \n",
              "4  function getTokenAtPosition(sourceFile, positi...   \n",
              "\n",
              "                                           docstring  \n",
              "0         #region Discovery, LanguageService & Setup  \n",
              "1  Read imports and follow them until all files h...  \n",
              "2  #endregion #region Utils \\nReturns the node's ...  \n",
              "3  Go to the original declaration for cases:  (1)...  \n",
              "4     Get the token whose text contains the position  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G663Ej03qpeE"
      },
      "source": [
        "# Data Cleaning  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JAoUoYdqpeF",
        "outputId": "ad52e597-9834-4aa4-a061-78dc4e5d6875",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((123889, 2), (8253, 2), (6483, 2))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def del_docstring_from_code(value):\n",
        "    \"\"\"\n",
        "    input : code and docstring\n",
        "    output clean code snippet  \n",
        "    \"\"\"\n",
        "    if value[1] in value[0]:\n",
        "        value[0] = value[0].replace(value[1] , \"\")\n",
        "\n",
        "\n",
        "    return value[0]\n",
        "\n",
        "\n",
        "train.code = [ del_docstring_from_code(value) for value in train.values]\n",
        "test.code  = [ del_docstring_from_code(value) for value in test.values]\n",
        "valid.code = [ del_docstring_from_code(value) for value in valid.values] \n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IKILMYuqpeF",
        "outputId": "e6980430-823b-4df3-b639-7a313a7daa40",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((123889, 2), (8253, 2), (6483, 2))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove html. tag from the code \n",
        "\n",
        "def remove_html(cmt):\n",
        "    \"\"\"\n",
        "    input  : Docstring\n",
        "    output : Clean comment  \n",
        "    \"\"\"\n",
        "    return re.sub(r\"<.?span[^>]*>|<.?code[^>]*>|<.?p[^>]*>|<.?hr[^>]*>|<.?h[1-3][^>]*>|<.?a[^>]*>|<.?b[^>]*>|<.?blockquote[^>]*>|<.?del[^>]*>|<.?dd[^>]*>|<.?dl[^>]*>|<.?dt[^>]*>|<.?em[^>]*>|<.?i[^>]*>|<.?img[^>]*>|<.?kbd[^>]*>|<.?li[^>]*>|<.?ol[^>]*>|<.?pre[^>]*>|<.?s[^>]*>|<.?sup[^>]*>|<.?sub[^>]*>|<.?strong[^>]*>|<.?strike[^>]*>|<.?ul[^>]*>|<.?br[^>]*>\", \"\", cmt)\n",
        "\n",
        "\n",
        "train.docstring = train.docstring.apply(lambda x : remove_html(x))\n",
        "test.docstring = test.docstring.apply(lambda x : remove_html(x))\n",
        "valid.docstring = valid.docstring.apply(lambda x : remove_html(x))\n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltzmPuDzqpeF",
        "outputId": "dadf4268-fae0-41c9-9a1a-bf2f83af23db",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((123889, 2), (8253, 2), (6483, 2))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get rid of the rowes that has < code > tag in there docstring \n",
        "\n",
        "def has_code(cmt) :\n",
        "    \n",
        "    '''\n",
        "    Determinine if the given comment contains the HTML <code> tag\n",
        "    '''\n",
        "\n",
        "    if '<code>' in cmt: return True\n",
        "    else: return False\n",
        "\n",
        "\n",
        "train = train[ ~ train.docstring.apply(lambda x : has_code(x) ) ]\n",
        "test  = test[ ~ test.docstring.apply(lambda x : has_code(x) ) ]\n",
        "valid = valid[ ~ valid.docstring.apply(lambda x : has_code(x) ) ]\n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlgKMfiIqpeG",
        "outputId": "dd1a2632-8ec2-4191-e40c-44703c6e5456",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((123889, 2), (8253, 2), (6483, 2))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# bring everything to lowercase and remove extra space\n",
        "\n",
        "train = train.applymap(lambda row : ' '.join(row.split()).lower())\n",
        "test = test.applymap(lambda row : ' '.join(row.split()).lower())\n",
        "valid = valid.applymap(lambda row : ' '.join(row.split()).lower())\n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHRkKE04qpeG",
        "outputId": "7f4526ce-bc8d-4f4e-8c00-4ffcb24a1ee4",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((106737, 2), (7153, 2), (5596, 2))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# delet the rows where the length of the docstring is longer than the length of the code! This is becase some time code comment tend to have extra \n",
        "# info which is not available in real time \n",
        "\n",
        "\n",
        "train = train[ ~ train.apply(lambda row : len(row.code) < len(row.docstring) , axis= 1 ) ]\n",
        "\n",
        "test = test[ ~ test.apply(lambda row : len(row.code) < len(row.docstring) , axis= 1 ) ]\n",
        "\n",
        "valid = valid[ ~ valid.apply(lambda row : len(row.code) < len(row.docstring) , axis= 1 ) ] \n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCOf6W8vqpeG",
        "outputId": "3aef15c6-d0af-45b7-e6a2-fb6f2b55d567",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((106734, 2), (7151, 2), (5596, 2))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove the rows that has missing docstring  \n",
        "\n",
        "train = train[ ~ ( train.docstring == '') ]\n",
        "test  = test[ ~ ( test.docstring == '') ]\n",
        "valid = valid[ ~ ( valid.docstring == '') ]\n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbY_U6SQqpeG",
        "outputId": "b293069f-a8d6-46f8-be56-00ab86cc12d6",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((98142, 2), (6677, 2), (5298, 2))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove duplicate values \n",
        "\n",
        "train = train[ ~ train.docstring.duplicated() ]\n",
        "test = test[ ~ test.docstring.duplicated() ]\n",
        "valid = valid[ ~ valid.docstring.duplicated() ]\n",
        "\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vON8-V0nHoiW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train = train.reset_index().drop(labels = 'index', axis = 1)\n",
        "test = test.reset_index().drop(labels = 'index', axis = 1)\n",
        "valid = valid.reset_index().drop(labels = 'index', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUtrkOfcqpeH"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdIcwbDSqpeH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# lets find the max length of both code and description sequence "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1jaEu1TqpeH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# initialise our tokenizer \n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EShsdYuqpeH",
        "outputId": "9d6cd2e3-8faa-41c3-aea6-37b3dab32404",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "code_lengths = [ len( tokenizer.encode( code, add_special_tokens= False ) ) for code in train.code.values ]\n",
        "\n",
        "cmt_lengths = [ len( tokenizer.encode( comment, add_special_tokens= False ) ) for comment in train.docstring.values ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "tQrtjBz4qpeH",
        "outputId": "e35315b1-f5ef-4668-9a3d-06982c32a08b",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot all the code lengths \n",
        "\n",
        "plt.plot(code_lengths)\n",
        "plt.title(\"length of all the code\")\n",
        "plt.ylabel(\"code length\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "j3Zq29v0qpeH",
        "outputId": "f76cdb36-fd3e-4064-8d09-8ff3076c347f",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot all comment lengths \n",
        "\n",
        "plt.plot(cmt_lengths)\n",
        "plt.title(\"length of all the comments\")\n",
        "plt.ylabel(\"comment length\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98LCmEGUqpeH"
      },
      "source": [
        "as we see from the above graph, its clear that we have some outliers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgMX13LkqpeI",
        "outputId": "45b262f1-271e-44a7-b2c9-2fdc3a1affdc",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(473, 78)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Outliers \n",
        "\n",
        "code_outlier, cmt_outlier = int( np.quantile(code_lengths, 0.90) ), int( np.quantile(cmt_lengths, 0.90)  )\n",
        "\n",
        "code_outlier, cmt_outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVNQup6xBTip",
        "outputId": "cf5436d5-a9a9-4fae-a034-f59e33da7664",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37.26497320209492"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add a piece of comment to code \n",
        "\n",
        "np.mean( cmt_lengths )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJxdfXMIqpeI",
        "outputId": "f20d00f5-a898-433d-a7b6-87a6155361e8",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(256, 64)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets only consider the average length of the code and comment \n",
        "\n",
        "code_max_length, cmt_max_length =  256  ,  64      # \"int(np.average(code_lengths))\", int(np.average(cmt_lengths)) \n",
        "\n",
        "code_max_length, cmt_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzLKd-V4tK9m",
        "outputId": "0a5a8e20-fb29-4746-b023-a2cd470a1628",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((67258, 2), (6677, 2), (5298, 2))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop all the records that are greater than 256\n",
        "\n",
        "long_code_index = [ i  for i, length in  enumerate( code_lengths ) if length > code_max_length ]\n",
        "\n",
        "# drop all the recodrs in the index\n",
        "train.drop(index = long_code_index, inplace = True)\n",
        "\n",
        "# reset index\n",
        "train = train.reset_index().drop(labels = 'index', axis = 1) \n",
        "\n",
        "\n",
        "# drop all the records that are greater than 64\n",
        "cmt_lengths = [ len( tokenizer.encode( comment, add_special_tokens= False ) ) for comment in train.docstring.values ]\n",
        "\n",
        "long_cmt_index = [ i  for i, length in  enumerate( cmt_lengths ) if length > cmt_max_length ]\n",
        "\n",
        "# drop all the recodrs in the index\n",
        "train.drop(index = long_cmt_index, inplace = True)\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cK97TcxqpeI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# let us tokenize the data \n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# To tokenize the code \n",
        "def code_tokenizer(data : list):\n",
        "    \"\"\"\n",
        "    input  :  list of code to be tokenized\n",
        "    output :  input_ids and attention_mask tensor of type long \n",
        "    \"\"\"\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_mask = [] \n",
        "\n",
        "    for str in data: \n",
        "        encoded = tokenizer.encode_plus( text= str , max_length= code_max_length, padding= 'max_length', truncation= True)\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_mask.append(encoded['attention_mask'])\n",
        "\n",
        "\n",
        "    # covert the input ids and the attention mask to type tensor \n",
        "    input_ids = torch.LongTensor(input_ids)\n",
        "    attention_mask = torch.LongTensor(attention_mask)\n",
        "\n",
        "    print(f\"shape of the code input_ids -> {input_ids.shape}\")\n",
        "    print(f\"shape of the code attention_mask -> {attention_mask.shape}\")\n",
        "\n",
        "    return input_ids, attention_mask \n",
        "\n",
        "\n",
        "# let us tokenize docstring \n",
        "def comment_tokenizer(data : list):\n",
        "    \"\"\"\n",
        "    input  :  list of comment to be tokenized\n",
        "    output :  input_ids and attention_mask tensor of type long \n",
        "    \"\"\"\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_mask = [] \n",
        "\n",
        "    for str in data: \n",
        "        encoded = tokenizer.encode_plus( text= str , max_length= cmt_max_length, padding= 'max_length', truncation= True)\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_mask.append(encoded['attention_mask'])\n",
        "\n",
        "\n",
        "    # covert the input ids and the attention mask to type tensor \n",
        "    input_ids = torch.LongTensor(input_ids)\n",
        "    attention_mask = torch.LongTensor(attention_mask)\n",
        "\n",
        "    print(f\"shape of the comment input_ids -> {input_ids.shape}\")\n",
        "    print(f\"shape of the comment attention_mask -> {attention_mask.shape}\")\n",
        "\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "\n",
        "# creating a dataloader \n",
        "def make_data_loader(data : pd.DataFrame ) -> torch.utils.data.DataLoader2 :\n",
        "    \"\"\"\n",
        "    input  : pandas data frame of code docstring pair \n",
        "    output : DataLaoder that has src_input_ids, src_attention_mask, tgt_input_ids, tgt_attention_mask\n",
        "    \"\"\"\n",
        "\n",
        "    assert 'code' in test.columns , \"rename the function column name to code \"\n",
        "    assert 'docstring' in test.columns , \"rename the description column name to docstring \"\n",
        "\n",
        "    SRC_input_ids, SRC_attention_mask  = code_tokenizer(data.code.values)          # reurns input ids and attention mask of both source  -> shape [N, S] \n",
        "    TGT_input_ids, TGT_attention_mask  = comment_tokenizer(data.docstring.values) # reurns input ids and attention mask of both source  -> shape [N, T] \n",
        "\n",
        "    data = torch.utils.data.TensorDataset( SRC_input_ids, SRC_attention_mask, TGT_input_ids, TGT_attention_mask ) # has four values in one variable \n",
        "\n",
        "    sampler =  torch.utils.data.RandomSampler(data)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(dataset= data, batch_size= BATCH_SIZE, num_workers= 3, drop_last=True, sampler= sampler) # shape [N, S] -> [batchsize, sequence length]\n",
        "    \n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTN0L97CqpeI",
        "outputId": "23209a79-cfe9-4312-c7cc-64dda18de1f8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For train data\n",
            "shape of the code input_ids -> torch.Size([67258, 256])\n",
            "shape of the code attention_mask -> torch.Size([67258, 256])\n",
            "shape of the comment input_ids -> torch.Size([67258, 64])\n",
            "shape of the comment attention_mask -> torch.Size([67258, 64])\n"
          ]
        }
      ],
      "source": [
        "# Function call to create a data loader for thge model\n",
        "\n",
        "print(\"For train data\")\n",
        "Train = make_data_loader(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "CfC2GHJyOXND",
        "outputId": "ed6721f0-e7b5-442f-a092-37cf6876fb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For validation data\n",
            "shape of the code input_ids -> torch.Size([6677, 256])\n",
            "shape of the code attention_mask -> torch.Size([6677, 256])\n",
            "shape of the comment input_ids -> torch.Size([6677, 64])\n",
            "shape of the comment attention_mask -> torch.Size([6677, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"For validation data\")\n",
        "Valid = make_data_loader(valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "iORfaVU4OXND",
        "outputId": "17d899a2-3c42-4fe4-cf21-f495a49544d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For test data\n",
            "shape of the code input_ids -> torch.Size([5298, 256])\n",
            "shape of the code attention_mask -> torch.Size([5298, 256])\n",
            "shape of the comment input_ids -> torch.Size([5298, 64])\n",
            "shape of the comment attention_mask -> torch.Size([5298, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"For test data\")\n",
        "Test = make_data_loader(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8JQ114DqpeI"
      },
      "source": [
        "## Develop model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g5_4AJJwkBY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Beam(object):\n",
        "    def __init__(self, size,sos,eos):\n",
        "        \n",
        "        \"\"\"\n",
        "        @article{DBLP:journals/corr/abs-2102-04664,\n",
        "          author    = {Shuai Lu and\n",
        "                       Daya Guo and\n",
        "                       Shuo Ren and\n",
        "                       Junjie Huang and\n",
        "                       Alexey Svyatkovskiy and\n",
        "                       Ambrosio Blanco and\n",
        "                       Colin B. Clement and\n",
        "                       Dawn Drain and\n",
        "                       Daxin Jiang and\n",
        "                       Duyu Tang and\n",
        "                       Ge Li and\n",
        "                       Lidong Zhou and\n",
        "                       Linjun Shou and\n",
        "                       Long Zhou and\n",
        "                       Michele Tufano and\n",
        "                       Ming Gong and\n",
        "                       Ming Zhou and\n",
        "                       Nan Duan and\n",
        "                       Neel Sundaresan and\n",
        "                       Shao Kun Deng and\n",
        "                       Shengyu Fu and\n",
        "                       Shujie Liu},\n",
        "          title     = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding\n",
        "                       and Generation},\n",
        "          journal   = {CoRR},\n",
        "          volume    = {abs/2102.04664},\n",
        "          year      = {2021}\n",
        "        }\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.tt = torch.cuda\n",
        "        # The score for each translation on the beam.\n",
        "        self.scores = self.tt.FloatTensor(size).zero_()\n",
        "        # The backpointers at each time-step.\n",
        "        self.prevKs = []\n",
        "        # The outputs at each time-step.\n",
        "        self.nextYs = [self.tt.LongTensor(size)\n",
        "                       .fill_(0)]\n",
        "        self.nextYs[0][0] = sos\n",
        "        # Has EOS topped the beam yet.\n",
        "        self._eos = eos\n",
        "        self.eosTop = False\n",
        "        # Time and k pair for finished.\n",
        "        self.finished = []\n",
        "\n",
        "    def getCurrentState(self):\n",
        "        \"Get the outputs for the current timestep.\"\n",
        "        batch = self.tt.LongTensor(self.nextYs[-1]).view(-1, 1)\n",
        "        return batch\n",
        "\n",
        "    def getCurrentOrigin(self):\n",
        "        \"Get the backpointers for the current timestep.\"\n",
        "        return self.prevKs[-1]\n",
        "\n",
        "    def advance(self, wordLk):\n",
        "        \"\"\"\n",
        "        Given prob over words for every last beam `wordLk` and attention\n",
        "        `attnOut`: Compute and update the beam search.\n",
        "        Parameters:\n",
        "        * `wordLk`- probs of advancing from the last step (K x words)\n",
        "        * `attnOut`- attention at the last step\n",
        "        Returns: True if beam search is complete.\n",
        "        \"\"\"\n",
        "        numWords = wordLk.size(1)\n",
        "\n",
        "        # Sum the previous scores.\n",
        "        if len(self.prevKs) > 0:\n",
        "            beamLk = wordLk + self.scores.unsqueeze(1).expand_as(wordLk)\n",
        "\n",
        "            # Don't let EOS have children.\n",
        "            for i in range(self.nextYs[-1].size(0)):\n",
        "                if self.nextYs[-1][i] == self._eos:\n",
        "                    beamLk[i] = -1e20\n",
        "        else:\n",
        "            beamLk = wordLk[0]\n",
        "        flatBeamLk = beamLk.view(-1)\n",
        "        bestScores, bestScoresId = flatBeamLk.topk(self.size, 0, True, True)\n",
        "\n",
        "        self.scores = bestScores\n",
        "\n",
        "        # bestScoresId is flattened beam x word array, so calculate which\n",
        "        # word and beam each score came from\n",
        "        prevK = bestScoresId // numWords\n",
        "        self.prevKs.append(prevK)\n",
        "        self.nextYs.append((bestScoresId - prevK * numWords))\n",
        "\n",
        "\n",
        "        for i in range(self.nextYs[-1].size(0)):\n",
        "            if self.nextYs[-1][i] == self._eos:\n",
        "                s = self.scores[i]\n",
        "                self.finished.append((s, len(self.nextYs) - 1, i))\n",
        "\n",
        "        # End condition is when top-of-beam is EOS and no global score.\n",
        "        if self.nextYs[-1][0] == self._eos:\n",
        "            self.eosTop = True\n",
        "\n",
        "    def done(self):\n",
        "        return self.eosTop and len(self.finished) >=self.size\n",
        "\n",
        "    def getFinal(self):\n",
        "        if len(self.finished) == 0:\n",
        "            self.finished.append((self.scores[0], len(self.nextYs) - 1, 0))\n",
        "        self.finished.sort(key=lambda a: -a[0])\n",
        "        if len(self.finished) != self.size:\n",
        "            unfinished=[]\n",
        "            for i in range(self.nextYs[-1].size(0)):\n",
        "                if self.nextYs[-1][i] != self._eos:\n",
        "                    s = self.scores[i]\n",
        "                    unfinished.append((s, len(self.nextYs) - 1, i)) \n",
        "            unfinished.sort(key=lambda a: -a[0])\n",
        "            self.finished+=unfinished[:self.size-len(self.finished)]\n",
        "        return self.finished[:self.size]\n",
        "\n",
        "    def getHyp(self, beam_res):\n",
        "        \"\"\"\n",
        "        Walk back to construct the full hypothesis.\n",
        "        \"\"\"\n",
        "        hyps=[]\n",
        "        for _,timestep, k in beam_res:\n",
        "            hyp = []\n",
        "            for j in range(len(self.prevKs[:timestep]) - 1, -1, -1):\n",
        "                hyp.append(self.nextYs[j+1][k])\n",
        "                k = self.prevKs[j][k]\n",
        "            hyps.append(hyp[::-1])\n",
        "        return hyps\n",
        "    \n",
        "    def buildTargetTokens(self, preds):\n",
        "        sentence=[]\n",
        "        for pred in preds:\n",
        "            tokens = []\n",
        "            for tok in pred:\n",
        "                if tok==self._eos:\n",
        "                    break\n",
        "                tokens.append(tok)\n",
        "            sentence.append(tokens)\n",
        "        return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RyFFFWVqpeI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Code_Comment_Generator(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, encoder, decoder, d_model, src_vocab_size, tgt_vocab_Size, pad_idx, dropout, src_max_length, tgt_max_length, config, lr, epoch, tokenizer ):\n",
        "\n",
        "        super(Code_Comment_Generator, self).__init__() \n",
        "\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.pad_idx = pad_idx\n",
        "        self.lr = lr\n",
        "        self.epoch = epoch\n",
        "        self.tgt_max_length = tgt_max_length #\n",
        "        self.beam_size = 10\n",
        "        self.sos_id = 0\n",
        "        self.eos_id =2\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.test_cases = []        \n",
        "        self.eval_counter = 0\n",
        "\n",
        "        # pretrained config \n",
        "        self.config = config\n",
        "\n",
        "        # Roberta Encoder  layer \n",
        "        self.encoder = encoder\n",
        "\n",
        "        # Decoder Transformers \n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "        # Register buffer \n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(2048, 2048))) # This is typically used to register a buffer that should not to be considered a model parameter.\n",
        "\n",
        "        # dense layers \n",
        "        self.dense_layer = nn.Linear(in_features= self.d_model, \n",
        "                                out_features= self.d_model)\n",
        "\n",
        "\n",
        "        # generator\n",
        "        self.generator = nn.Linear(in_features= self.d_model, \n",
        "                                out_features= tgt_vocab_Size,  bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # final activation \n",
        "        self.log_softmax = nn.LogSoftmax(dim= -1)\n",
        "        \n",
        "        # sharing weights between the encoder and the decoder \n",
        "        self.share_weights() \n",
        "\n",
        "        \n",
        "\n",
        "    def share_weights(self):\n",
        "        \"\"\" \n",
        "            This is to ensure we are sharing weights between the encoder and fianl dense layer \n",
        "        \"\"\"\n",
        "\n",
        "        if self.config.torchscript:\n",
        "            self.generator.weight = nn.Parameter( data =  self.encoder.embeddings.word_embeddings.weight.clone()) \n",
        "        \n",
        "        else: \n",
        "            self.generator.weight = self.encoder.embeddings.word_embeddings.weight\n",
        "\n",
        "    \n",
        "    def forward(self, src = None, src_key_padding_mask= None, tgt= None, tgt_key_padding_mask= None):\n",
        "        \"\"\" \n",
        "        input  : source and taget tokens and attention mask \n",
        "        output : logits\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # encoder output, this gives us the context vector which is present in the last decoder layer \n",
        "\n",
        "        encoder_output = self.encoder(src, attention_mask = src_key_padding_mask )[0]# considering the output of the last encoder layer  : shape -> torch.Size([32, 212, 768]) -> [N,S,E]\n",
        "        encoder_output = encoder_output.permute([1,0,2]).contiguous() # rearanging tensor to shape -> torch.Size([212,32,768]) -> [S,N,E] \n",
        "\n",
        "        if tgt is not None: \n",
        "\n",
        "          tgt_mask = -1e4 *(1-self.bias[:tgt.shape[1],:tgt.shape[1]]).to(device= device) # shape -> trg_mask > torch.Size([42, 42])\n",
        "      \n",
        "          # encode the target embeddings \n",
        "          tgt_embedding = self.encoder.embeddings(tgt)                    # shape: torch.Size([32, 42, 768]) -> [N, T, E]\n",
        "          tgt_embedding = tgt_embedding.permute([1,0,2]).contiguous()     # shape: torch.Size([42, 32, 768]) -> [T, N, E]\n",
        "\n",
        "          # memeory key padding mask \n",
        "          memory_key_padding_mask = (1-src_key_padding_mask).bool()      # shape : torch.Size([32, 212])     -> [N, E]\n",
        "        \n",
        "        \n",
        "          # output of the decoder \n",
        "          output = self.decoder(tgt = tgt_embedding, \n",
        "                                  memory = encoder_output, \n",
        "                                  tgt_mask = tgt_mask, \n",
        "                                  memory_key_padding_mask = memory_key_padding_mask )               # torch.Size([42, 32, 768]) -> T, N, E\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          output =    torch.tanh( self.dropout(   self.dense_layer(output)  ) ).permute([1,0,2]).contiguous()  # activation + FC_1         # torch.Size([42, 32, 768])  -> T, N, E\n",
        "\n",
        "          output =  self.generator(output)                    # output shape :- torch.Size([42, 32, 50265]) -> T, N, TGT_Vocb_size\n",
        "\n",
        "\n",
        "          # calculate loss \n",
        "          active_loss = tgt_key_padding_mask[: , 1: ].ne(0).view(-1) == 1      # shape -> torch.Size([1312]) N*(T-1)\n",
        "\n",
        "          shift_logits = output[:, :-1, :].contiguous()                        # shape -> torch.Size([32, 41, 50265]) N, (T-1), TGT_vocab_size\n",
        "\n",
        "          shift_labels = tgt[:, 1:].contiguous()                            # shape -> torch.Size([32, 41])        N, (T-1)\n",
        "\n",
        "\n",
        "          # flatten the tokens and find the loss \n",
        "          y_hat = shift_logits.view(-1, shift_logits.shape[-1])[active_loss]  # predicted value flatened\n",
        "          y     = shift_labels.view(-1)[active_loss]                          # actual value flatten\n",
        "\n",
        "          # find the cross entropy loss \n",
        "          loss = F.cross_entropy(y_hat ,  y , ignore_index = self.pad_idx )\n",
        "\n",
        "          # memory management \n",
        "          del output\n",
        "          torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "          pl.utilities.memory.garbage_collection_cuda()\n",
        "          pl.utilities.memory.get_gpu_memory_map()\n",
        "          \n",
        "\n",
        "          return loss #, loss*active_loss.sum() # train loss, evaluation loss \n",
        "        \n",
        "        else: \n",
        "          # prediction \n",
        "          preds = []\n",
        "\n",
        "          zero=torch.cuda.LongTensor(1).fill_(0)\n",
        "\n",
        "          for i in range(src.shape[0]):\n",
        "\n",
        "            context = encoder_output[:,i:i+1]\n",
        "\n",
        "            context_mask = src_key_padding_mask[i:i+1,:]\n",
        "\n",
        "            beam = Beam(self.beam_size, self.sos_id, self.eos_id) ####\n",
        "\n",
        "            input_ids=beam.getCurrentState()\n",
        "\n",
        "            context=context.repeat(1, self.beam_size,1)\n",
        "\n",
        "            context_mask=context_mask.repeat(self.beam_size,1)     \n",
        "\n",
        "            for _ in range(self.tgt_max_length):   #######\n",
        "              \n",
        "              if beam.done():\n",
        "                break\n",
        "\n",
        "              tgt_mask=-1e4 *(1-self.bias[:input_ids.shape[1],:input_ids.shape[1]]) \n",
        "\n",
        "              tgt_embedding = self.encoder.embeddings(input_ids).permute([1,0,2]).contiguous() \n",
        "\n",
        "              # memeory key padding mask \n",
        "              memory_key_padding_mask = (1-context_mask).bool()      # shape : torch.Size([32, 212])     -> [N, E]\n",
        "            \n",
        "            \n",
        "              # output of the decoder \n",
        "              output = self.decoder(tgt = tgt_embedding, \n",
        "                                      memory = context, \n",
        "                                      tgt_mask = tgt_mask, \n",
        "                                      memory_key_padding_mask = memory_key_padding_mask )               # torch.Size([42, 32, 768]) -> T, N, E\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              output =  torch.tanh( self.dropout(   self.dense_layer(output)  ) ).permute([1,0,2]).contiguous()[:,-1,:]  # activation + FC_1         # torch.Size([42, 32, 768])  -> T, N, E\n",
        "\n",
        "              output =  self.log_softmax( self.generator(output) ).data               # output shape :- torch.Size([42, 32, 50265]) -> T, N, TGT_Vocb_size\n",
        "\n",
        "              beam.advance(output)\n",
        "\n",
        "              input_ids.data.copy_(input_ids.data.index_select(0, beam.getCurrentOrigin()))\n",
        "              input_ids=torch.cat((input_ids,beam.getCurrentState()),-1)\n",
        "\n",
        "            hyp= beam.getHyp(beam.getFinal())\n",
        "            pred=beam.buildTargetTokens(hyp)[:self.beam_size]\n",
        "            pred=[torch.cat([x.view(-1) for x in p]+[zero]*(self.tgt_max_length -len(p))).view(1,-1) for p in pred]\n",
        "            preds.append(torch.cat(pred,0).unsqueeze(0))\n",
        "          \n",
        "          preds=torch.cat(preds,0)   \n",
        "\n",
        "          del output\n",
        "          del context\n",
        "          torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "          pl.utilities.memory.garbage_collection_cuda()\n",
        "          pl.utilities.memory.get_gpu_memory_map() \n",
        "\n",
        "          return preds\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_indx): \n",
        "\n",
        "\n",
        "        # train model\n",
        "        self.train()\n",
        "\n",
        "        # unrap and load all the trensors to device\n",
        "        src, src_key_padding_mask, tgt, tgt_key_padding_mask = tuple( i.to(device) for i in batch)\n",
        "\n",
        "        #returns loss\n",
        "        Loss  = self( src, src_key_padding_mask, tgt, tgt_key_padding_mask )\n",
        "\n",
        "        # log the loss \n",
        "        self.log(name= \"tran_loss\", value= Loss, on_step= True, on_epoch=True, prog_bar= True, logger= True)\n",
        "\n",
        "        # memory management\n",
        "        gc.collect()\n",
        "        pl.utilities.memory.garbage_collection_cuda()\n",
        "        pl.utilities.memory.get_gpu_memory_map()\n",
        "\n",
        "        return Loss\n",
        "\n",
        "    def validation_step(self, batch, batch_indx): \n",
        "\n",
        "\n",
        "        # evaluate model\n",
        "        self.eval()\n",
        "\n",
        "        if self.eval_counter == 400 : # self.train_dataloader().batch_size\n",
        "\n",
        "          code = \" def search_features(self, search): if isinstance(search, string_types): search = [search] search = [s.replace('*', '.*') for s in search] cols = list(self.data.columns) results = [] for s in search: results.extend([f for f in cols if re.match(s + '$', f)]) return list(set(results)) \" \n",
        "          doc = \"returns all features that match any of the elements in the input list.\"\n",
        "\n",
        "          print(f\"generated cmt : {self.generate_comment(code) }\")\n",
        "          print(f\"original cmt : {doc}\")  \n",
        "\n",
        "          self.test_cases.append(self.generate_comment(code))\n",
        "\n",
        "          self.eval_counter = 0\n",
        "\n",
        "\n",
        "        self.eval_counter += 1\n",
        "\n",
        "        # unrap and load all the trensors to device\n",
        "        src, src_key_padding_mask, tgt, tgt_key_padding_mask = tuple( i.to(device) for i in batch)\n",
        "\n",
        "        #returns loss\n",
        "        Loss  = self( src, src_key_padding_mask, tgt, tgt_key_padding_mask )\n",
        "\n",
        "\n",
        "        # log the loss \n",
        "        self.log(name= \"validation_loss\", value= Loss, on_step= True, on_epoch=True, prog_bar= True, logger= True)\n",
        "\n",
        "        # memory management\n",
        "        gc.collect()\n",
        "        pl.utilities.memory.garbage_collection_cuda()\n",
        "        pl.utilities.memory.get_gpu_memory_map()\n",
        "\n",
        "        return Loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "\n",
        "\n",
        "        # Prepare optimizer and schedule (linear warmup and decay)\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'weight_decay': 0.0 },\n",
        "            {'params': [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "        \n",
        "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr = self.lr , eps= 1e-8 )\n",
        "        \n",
        "        nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
        "\n",
        "        torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "        lr_scheduler = {\n",
        "            'scheduler' : transformers.get_linear_schedule_with_warmup(optimizer= optimizer, num_warmup_steps = 5000, num_training_steps= self.epoch * len(Test)  ), \n",
        "            'interval'  : \"step\", \n",
        "            'frequency' : 1, \n",
        "            'monitor'   : \"validation_loss\", \n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "\n",
        "      return  Train\n",
        "\n",
        "    def val_dataloader(self):    \n",
        "\n",
        "      return Valid\n",
        "\n",
        "\n",
        "    def generate_comment(self, code):\n",
        "      \"\"\"\n",
        "      input : single code string \n",
        "      output : Generated comment \n",
        "      \"\"\"\n",
        "\n",
        "      tokenized = self.tokenizer.encode_plus(code, max_length= 256, padding='max_length', return_attention_mask= True, truncation= True )\n",
        "\n",
        "      src = torch.LongTensor(tokenized['input_ids'] ).unsqueeze(1).reshape(1,-1).to(device)\n",
        "      src_key_padding_mask = torch.LongTensor(tokenized['attention_mask'] ).unsqueeze(1).reshape(1,-1).to(device)\n",
        "\n",
        "      gen_cmt = []\n",
        "\n",
        "      preds = self(src, src_key_padding_mask)\n",
        "\n",
        "      for pred in preds:\n",
        "        t  = pred[0].cpu().numpy()\n",
        "        t=list(t)\n",
        "        if 0 in t:\n",
        "          t=t[:t.index(0)]\n",
        "        text = self.tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
        "        \n",
        "        gen_cmt.append(text)\n",
        "\n",
        "      return gen_cmt\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEP_Ewo_qpeJ",
        "outputId": "adeb300b-3e27-424b-b4c1-80fdf1b3698b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyedjunaidiqbal\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# log in to weight and bias \n",
        "\n",
        "wandb.login()\n",
        "\n",
        "# !wandb login --relogin. # eff91dd48ca6e7c55dfef9359e810cf3747cd6a2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRn-YStVqpeJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLbYf80vkc6N",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#pretrained configuration\n",
        "config = transformers.RobertaConfig.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "d_model = config.hidden_size\n",
        "src_vocab_size = tokenizer.vocab_size\n",
        "tgt_vocab_Size = tokenizer.vocab_size\n",
        "pad_idx = tokenizer.pad_token_id\n",
        "dropout = 0.5\n",
        "src_max_length = code_max_length\n",
        "tgt_max_length = cmt_max_length\n",
        "epoch = 1000\n",
        "lr = 5e-5\n",
        "\n",
        "# object of seq2seql model\n",
        "# seq2seql = Seq2Seq(d_model, src_vocab_size, tgt_vocab_Size, pad_idx, dropout, src_max_length, tgt_max_length, encoder, decoder, config ).to(device = device)\n",
        "\n",
        "# Roberta Encoder  layer \n",
        "encoder = transformers.RobertaModel.from_pretrained(pretrained_model_name_or_path= \"microsoft/codebert-base\", config =  config ) \n",
        "\n",
        "\n",
        "# Decoder Transformers \n",
        "decoder_layer = torch.nn.TransformerDecoderLayer(d_model= config.hidden_size, nhead= config.num_attention_heads)\n",
        "decoder = torch.nn.TransformerDecoder(decoder_layer= decoder_layer, num_layers= 6)\n",
        "\n",
        "# lightning model \n",
        "model = Code_Comment_Generator(encoder, decoder, d_model, src_vocab_size, tgt_vocab_Size, pad_idx, dropout, src_max_length, tgt_max_length, config, lr, epoch, tokenizer).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmhjcglGqpeJ",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "245e7803-2d0c-4d09-9c50-154f209aba95",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./saved_javascript_model_weights/wandb/run-20220811_091442-10rtzfnn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/syedjunaidiqbal/Desertation_Final_extras/runs/10rtzfnn\" target=\"_blank\">Transformers_for_javascript_Code_Comment_Generator_code_size_256_with_code_comment</a></strong> to <a href=\"https://wandb.ai/syedjunaidiqbal/Desertation_Final_extras\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# lightning configuration\n",
        "\n",
        "lr_monitor = LearningRateMonitor(logging_interval = \"step\" )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor= \"validation_loss\", \n",
        "                               min_delta = 0.001,\n",
        "                               patience= 5, \n",
        "                               strict= True, \n",
        "                               verbose= True, \n",
        "                               mode = 'min') \n",
        "\n",
        "model_checkpoint = ModelCheckpoint(dirpath= f\"./saved_{language}_model_weights/\", \n",
        "                                   save_last=True, \n",
        "                                   monitor=\"validation_loss\",  \n",
        "                                   save_on_train_epoch_end = True, \n",
        "                                   mode=\"min\", \n",
        "                                   save_top_k = 0)\n",
        "\n",
        "\n",
        "wandb_logger = WandbLogger(name= f'Transformers_for_{language}_Code_Comment_Generator_code_size_256_with_code_comment', \n",
        "                           project='Desertation_Final_extras', \n",
        "                           log_model= True, \n",
        "                           save_dir = f\"./saved_{language}_model_weights/\" )\n",
        "\n",
        "wandb_logger.watch(model, log=\"all\")\n",
        "\n",
        "trainer = Trainer(callbacks= [lr_monitor, early_stopping, model_checkpoint], \n",
        "                  devices= 1 , \n",
        "                  gradient_clip_algorithm= 'norm', \n",
        "                  accelerator='gpu', \n",
        "                  enable_progress_bar= True, \n",
        "                  default_root_dir = f\"./saved_{language}_model_weights/default_root_dir/\", \n",
        "                  max_epochs = epoch , \n",
        "                  logger = wandb_logger, \n",
        "                  strategy=\"dp\" , precision=16) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained weights if available, else train from scratch \n",
        " \n",
        "if os.path.exists(\"/content/models\"):\n",
        "\n",
        "  checkpoint = torch.load(load_model)\n",
        "  model.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "id": "1PecxDXCQBNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "00942e804e6a4b65aca7f1dc8a23f57a",
            "1b794ec3dcf6473199a81e021c90208c",
            "31070e366a454090845c4d7ba0364518",
            "0e59d43823804ecc8e1c1d539b3d22b3",
            "febd047a37e14b05b9d705fe8fd388ab",
            "022d2db88e4142bf9dbbf15d784b54ee",
            "23d868d9438745b2ba764e7993d1cd5f",
            "04531e3fe03843b6b51e9acc11490eeb",
            "93b1819f534c4eccb15ffbd1dd1dd959",
            "4bf32dea85d54ccbaa3f5e4f8e442f56",
            "bee45f87e44c42c19a130c8dcd1ed02e",
            "9734fc1840c54bc1913b2df69cbe732a",
            "caff0d7acb444bc6bb1083c726cec710",
            "def1b9a22aa14dfe9ed934d1b3248674",
            "6596dc4f56f14264a1fd59d42f8a62a9",
            "e8f234ff8caf4edc99e6b688a5cc4aad",
            "e4e7543cb1b845c9b48dce4eb96be292",
            "a81264bcda4742b88519caaf0776fd43",
            "9cf7873e2a6b4641b4b02d0942fdca4a",
            "df72278aece747fabadb28de1c23d398",
            "6398d0ef0b32464d9326e231f15eb637",
            "aec1582cccd34a8a8830d182c9ee8bbb",
            "e30b48b1179e4de1a862abe0350e305a",
            "c8b8bac5669a4c06a480f50e31e96ed0",
            "a1a2997a83874334ad83aa7b72d1096a",
            "2332c7e21c724fc6bbf2f834a9279b87",
            "afa48916f38e44488f20147dcb44403b",
            "fae7af95692846c58bf748d5de544b84",
            "09510aa60f344e91bcaba38d9b9ab4d7",
            "1df3aec6bfd445f3a2929540dd6c0944",
            "5edd7b6cd2cd4a968c504a0e75ea70cb",
            "33575d1d4fbf4cf3a78384481a83d7a1",
            "7446f38ab0284a259f90e21fd64ada11",
            "",
            "aaab5fa39df4475f92c638b567f12b86"
          ]
        },
        "id": "bECiWq2RqpeJ",
        "outputId": "92efbdcf-f8ba-41ab-eb61-3413e9318c50",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type               | Params\n",
            "---------------------------------------------------\n",
            "0 | encoder     | RobertaModel       | 124 M \n",
            "1 | decoder     | TransformerDecoder | 47.3 M\n",
            "2 | dense_layer | Linear             | 590 K \n",
            "3 | generator   | Linear             | 38.6 M\n",
            "4 | dropout     | Dropout            | 0     \n",
            "5 | log_softmax | LogSoftmax         | 0     \n",
            "---------------------------------------------------\n",
            "172 M     Trainable params\n",
            "0         Non-trainable params\n",
            "172 M     Total params\n",
            "345.007   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaab5fa39df4475f92c638b567f12b86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved. New best score: 5.409\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated cmt : ['returns the list of the given list of the given list of the given list of the given list of the given list of the given list. @param {array} search @param {array} searcharray @return {array}']\n",
            "original cmt : returns all features that match any of the elements in the input list.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved by 0.686 >= min_delta = 0.001. New best score: 4.723\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved by 0.442 >= min_delta = 0.001. New best score: 4.282\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated cmt : ['returns the list of features in the list of features']\n",
            "original cmt : returns all features that match any of the elements in the input list.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved by 0.174 >= min_delta = 0.001. New best score: 4.108\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved by 0.151 >= min_delta = 0.001. New best score: 3.957\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated cmt : ['search for features']\n",
            "original cmt : returns all features that match any of the elements in the input list.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metric validation_loss improved by 0.018 >= min_delta = 0.001. New best score: 3.938\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTt5o02EqpeJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,600000000)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNa0Pwg5OXNG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "65f816f3116ecd6eed356d511655e1457ced5db72acd8ea8583081b213683f9f"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00942e804e6a4b65aca7f1dc8a23f57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b794ec3dcf6473199a81e021c90208c",
              "IPY_MODEL_31070e366a454090845c4d7ba0364518",
              "IPY_MODEL_0e59d43823804ecc8e1c1d539b3d22b3"
            ],
            "layout": "IPY_MODEL_febd047a37e14b05b9d705fe8fd388ab"
          }
        },
        "022d2db88e4142bf9dbbf15d784b54ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04531e3fe03843b6b51e9acc11490eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09510aa60f344e91bcaba38d9b9ab4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e59d43823804ecc8e1c1d539b3d22b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf32dea85d54ccbaa3f5e4f8e442f56",
            "placeholder": "​",
            "style": "IPY_MODEL_bee45f87e44c42c19a130c8dcd1ed02e",
            "value": " 2/2 [00:03&lt;00:00,  1.94s/it]"
          }
        },
        "1b794ec3dcf6473199a81e021c90208c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022d2db88e4142bf9dbbf15d784b54ee",
            "placeholder": "​",
            "style": "IPY_MODEL_23d868d9438745b2ba764e7993d1cd5f",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "1df3aec6bfd445f3a2929540dd6c0944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2332c7e21c724fc6bbf2f834a9279b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33575d1d4fbf4cf3a78384481a83d7a1",
            "placeholder": "​",
            "style": "IPY_MODEL_7446f38ab0284a259f90e21fd64ada11",
            "value": " 535/535 [15:20&lt;00:00,  1.72s/it]"
          }
        },
        "23d868d9438745b2ba764e7993d1cd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31070e366a454090845c4d7ba0364518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04531e3fe03843b6b51e9acc11490eeb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93b1819f534c4eccb15ffbd1dd1dd959",
            "value": 2
          }
        },
        "33575d1d4fbf4cf3a78384481a83d7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf32dea85d54ccbaa3f5e4f8e442f56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5edd7b6cd2cd4a968c504a0e75ea70cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6398d0ef0b32464d9326e231f15eb637": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6596dc4f56f14264a1fd59d42f8a62a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6398d0ef0b32464d9326e231f15eb637",
            "placeholder": "​",
            "style": "IPY_MODEL_aec1582cccd34a8a8830d182c9ee8bbb",
            "value": " 420/7269 [18:53&lt;5:08:09,  2.70s/it, loss=4.04, v_num=iogm, tran_loss_step=4.310, validation_loss_step=4.650, validation_loss_epoch=4.730, tran_loss_epoch=5.340]"
          }
        },
        "7446f38ab0284a259f90e21fd64ada11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93b1819f534c4eccb15ffbd1dd1dd959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9734fc1840c54bc1913b2df69cbe732a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caff0d7acb444bc6bb1083c726cec710",
              "IPY_MODEL_def1b9a22aa14dfe9ed934d1b3248674",
              "IPY_MODEL_6596dc4f56f14264a1fd59d42f8a62a9"
            ],
            "layout": "IPY_MODEL_e8f234ff8caf4edc99e6b688a5cc4aad"
          }
        },
        "9cf7873e2a6b4641b4b02d0942fdca4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a2997a83874334ad83aa7b72d1096a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df3aec6bfd445f3a2929540dd6c0944",
            "max": 535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5edd7b6cd2cd4a968c504a0e75ea70cb",
            "value": 535
          }
        },
        "a81264bcda4742b88519caaf0776fd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec1582cccd34a8a8830d182c9ee8bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa48916f38e44488f20147dcb44403b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "bee45f87e44c42c19a130c8dcd1ed02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8b8bac5669a4c06a480f50e31e96ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae7af95692846c58bf748d5de544b84",
            "placeholder": "​",
            "style": "IPY_MODEL_09510aa60f344e91bcaba38d9b9ab4d7",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "caff0d7acb444bc6bb1083c726cec710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4e7543cb1b845c9b48dce4eb96be292",
            "placeholder": "​",
            "style": "IPY_MODEL_a81264bcda4742b88519caaf0776fd43",
            "value": "Epoch 1:   6%"
          }
        },
        "def1b9a22aa14dfe9ed934d1b3248674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf7873e2a6b4641b4b02d0942fdca4a",
            "max": 7269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df72278aece747fabadb28de1c23d398",
            "value": 420
          }
        },
        "df72278aece747fabadb28de1c23d398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e30b48b1179e4de1a862abe0350e305a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b8bac5669a4c06a480f50e31e96ed0",
              "IPY_MODEL_a1a2997a83874334ad83aa7b72d1096a",
              "IPY_MODEL_2332c7e21c724fc6bbf2f834a9279b87"
            ],
            "layout": "IPY_MODEL_afa48916f38e44488f20147dcb44403b"
          }
        },
        "e4e7543cb1b845c9b48dce4eb96be292": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f234ff8caf4edc99e6b688a5cc4aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fae7af95692846c58bf748d5de544b84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "febd047a37e14b05b9d705fe8fd388ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}